---
title: "BE601 - DATA ANALYTICS I"
subtitle: "Describing Data: Numerical"
author: "Uyen Vu"
date: "29/08/2022"
output: word_document
monofont: 'consolas'
---

# Measures of central tendency and location

1. Mean, Median, and Mode (describe central tendency)
- arithmetic mean:
- median: odd n vs even n
- mode: most regular observation **
  + one mode: unimodal distribution
  + two modes: bimodal distribution
  + > two modes: multimodal distribution
2. Example

```{r}
#exp 2.1 (p65)
demand <- c(60,84,65,67,75,72,80,85,63,82,70,75)
mean(demand)
median(demand)
df <- as.data.frame(table(demand))
colnames(df) <- c("value","freq")
df <- df[order(-df[, "freq"]), ]
df #mode is 75
```

```{r}
#exp 2.2 (p65)
eps <- c(0.05,0.05,0.081,0.136,0.232,0.207,0.12,0.142)
mean(eps)
median(eps)
df <- as.data.frame(table(eps))
colnames(df) <- c("value","freq")
df <- df[order(-df[, "freq"]), ]
df
```

3. Geometric mean

4. Percentiles and Quartiles
- five-number summary: minimum < Q1 < Median < Q3 < maximum
- **box-and-whisker plot** is used to describe five-number summary

```{r}
#exp 2.5
demand <- c(60,84,65,67,75,72,80,85,63,82,70,75)
demand <- sort(demand)
demand
fivenum(demand)
```

```{r}
#exp 2.6
shopping <- c(18,46,45,20,33,33,21,31,23,34,42,38,31,38,21,37,37,30,42,34,34,18,30,48,51,52,19,37,30,25,42,41,34,50,52,50,19,21,34,25,18,25,25,43,59,37,23,23,40,31,45,51,45,60,30,40,37,21,34,34,42,43,60,40,37,20,40,18,21,52,18,68,28,57,63,57,63,31,67,25,69,34,69,57,69,57,70,18,70,70,71,73,73,71,70,69,68,64,59,18,47,52,55,25)
shopping <- sort(shopping)
shopping
q1_position <- 0.25*(length(shopping)+1)
q1 <- 28 + 0.25*(30-28)
q1
fivenum(shopping)
```


# Shape of distribution

1. **skewness**
- Skewness is positive: skewed-right (mean > median)
- skewness is negative: skewed-left (mean < median)

2. R
- Base R does not have the function to calculate skewness
- Package **"moment"** with the command **skewness()**

# Measures of variability

1. **Range** = max - min
2. **IQR** and **box-and-whisker plot**
- Interquartile range (IQR) = Q3 - Q1 (remove the lowest 25% of the data and the highest 25% of the data)
- Box-and-Whisker Plot
3. **variance** and **standard deviation**

```{r}
#exp 2.8, p74
sales <- data.frame(Location_1 = c(6,8,10,12,14,9,11,7,13,11),
                    Location_2 = c(1,19,2,18,11,10,3,17,4,17),
                    Location_3 = c(2,3,25,20,22,19,25,20,22,26),
                    Location_4 = c(22,20,10,13,12,10,11,9,10,8))
sales
summary(sales)
sapply(sales,IQR)
boxplot(sales$Location_1, sales$Location_2, sales$Location_3, sales$Location_4,
        main = "Sales by location",
        ylab = "Sales",
        at = c(1,2,3,4),
        names = c("Location 1","Location 2","Location 3","Location 4"),
        col = "orange",
        border = "orange")
```

```{r}
#exp 2.9, p76
sales <- c(6,8,10,12,14,9,11,7,13,11)
mean(sales)
mean <- rep(mean(sales), 10)
df <- as.data.frame(cbind(sales,mean))
df
df$s_diff_m <- df$sales - df$mean
df$s_diff_m_sq <- df$s_diff_m^2
var <- sum(df$s_diff_m_sq)/(length(sales)-1)
var
sd <- var^0.5
sd
var(sales)
sd(sales)
```

4. Coefficient of Variation
- to adjust standard deviation as percentage of mean (unadjusted sd is biased when we try to compare 2 datasets of means of large difference)

```{r}
df <- data.frame(a=c(88, 85, 82, 97, 67, 77, 74, 86, 81, 95),
                   b=c(77, 88, 85, 76, 81, 82, 88, 91, 92, 99),
                   c=c(67, 68, 68, 74, 74, 76, 76, 77, 78, 84))
df
CV <- sapply(df, function(x) sd(x)/mean(x)*100)
CV
```

5. Chebyshev's theorem and the empirical rule

- Chebyshev's theorem: For any population with unknown distribution, with mean and sd, k > 1 is the number of sd, the percentage of observations that lie within the interval **[mean +/- sd*k]** is 
**100[1 - 1/k^2]%**

- Empirical rule: For large population with bell-shaped distribution:
  + approximately 68% of the obs are in the interval [mean +/- 1sd]
  + approximately 95% of the obs are in the interval [mean +/- 2sd]
  + almost all of the obs are in the interval [mean +/- 3sd]
  
```{r}
#exp 2.13
mean <- 1200
sd <- 50
#If shape of distribution is unknown: apply Chebyshev theorem
interval1_min <- mean - 1.5*sd
interval1_min
interval1_max <- mean + 1.5*sd
interval1_max
interval2_min <- mean - 2*sd
interval2_min
interval2_max <- mean + 2*sd
interval2_max
interval3_min <- mean - 3*sd
interval3_min
interval3_max <- mean + 3*sd
interval3_max
k1_5 <- 100*(1-1/(1.5^2))
k1_5
k2 <- 100*(1-1/(2^2))
k2
k3 <- 100*(1-1/3^2)
k3
#If shape of distribution is known as bell-shape: apply empirical rule
```

6. z-score

- percentile & quartiles: location of a value **relative to the entire dataset**

- z-Score: location of a value **relative to the mean of distribution**
  + number of sd that a value is from the mean
  + >0: value > mean
  + =0: value = mean
  + <0: value < mean
  + **z-score = (value of x - mean)/sd**
  

```{r}
#exp 2.14
mean <- 1200
sd <- 50
z_1120 <- (1120-1200)/50
z_1120
```

# Weighted mean and measure of grouped data

- Approximate mean and variance for grouped data is used when we don't know the exact value (e.g. a person is asked to choose his age range between 20 - 29 rather than giving an exact value)

# Measures of relationships between variables
- **scatterplot** is used as a graphical way of describing relationship
- **covariance** and **correlation** are used as numerical ways

```{r}
post <- c(16,31,27,23,15,17,17,18,14)
interaction <- c(165,314,280,195,137,286,199,128,462)
df <- as.data.frame(cbind(post,interaction))
df$mean_post <- mean(df$post)
df$mean_int <- mean(df$interaction)
df$mean_post_diff <- df$post - df$mean_post
df$mean_int_diff <- df$interaction - df$mean_int
df$mean_diff_prod <- df$mean_post_diff*df$mean_int_diff
cov_manual <- sum(df$mean_diff_prod)/(nrow(df)-1)
cov_manual
cov_r <- cov(post,interaction)
cov_r
df$mean_post_diff_sq <- df$mean_post_diff^2
df$mean_int_diff_sq <- df$mean_int_diff^2
var_post <- sum(df$mean_post_diff_sq)/(nrow(df)-1)
var_int <- sum(df$mean_int_diff_sq)/(nrow(df)-1)
cor_manual <- cov_manual/(var_post^0.5 * var_int^0.5)
cor_manual
cor_r <- cor(post,interaction, method = "pearson")
cor_r
```

